<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Ashe Neth's Personal Website</title>

    <meta charset="UTF-8">
    <meta name="keywords" content="Ashe, Neth, aneth, asheneth">
    <meta name="description" content="Ashe Neth's Personal Website">
    <meta name="author" content="Ashe Neth">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="css/colors.css">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/cards.css">
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/comic-mono@0.0.1/index.css">
  </head>
  <body>
    <div class="header">
      <div style="margin-left: 10px;">
        <a href="/" style="color: var(--header-text-color);">
          <h1>
            Ashe Neth
          </h1>
        </a>
      </div>

      <div style="margin-left: auto; margin-right: 10px;">
        <a href="files/cv.pdf" target="_blank">
          <h1>
            CV
          </h1>
        </a>
      </div>
    </div>

    <div class="content">
      <h2>
        About me:
      </h2>

      <div style="display: block; overflow: hidden;">
        <div style="display: flex; flex-direction: column; align-items: center; width: calc(var(--content-width) / 4); margin: 20px; float: left;">
          <img src="img/misc/face.jpeg" style="object-fit: cover; width: calc((var(--content-width) / 4) - 10px); height: calc((var(--content-width) / 4) - 10px); float: left; margin: 25px; border-radius: 50%; border: solid; border-color: var(--card-border-color); border-width: 5px;">
        
          <div class="contact">
            <a href="https://github.com/asheneth" target="_blank">
              <div class="icon" aria-hidden="true">
                <svg viewBox="0 0 24 24" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--text-color)>
                  <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z">
                  </path>
                </svg>
              </div>
            </a>

            <a href="https://www.linkedin.com/in/ashe-neth/" target="_blank">
              <div class="icon" aria-hidden="true">
                <svg viewBox="0 0 27 27" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--text-color)>
                  <path d="M1.91 0h22.363a1.91 1.91 0 011.909 1.91v22.363a1.91 1.91 0 01-1.91 1.909H1.91A1.91 1.91 0 010 24.272V1.91A1.91 1.91 0 011.91 0zm1.908 22.364h3.818V9.818H3.818zM8.182 5.727a2.455 2.455 0 10-4.91 0 2.455 2.455 0 004.91 0zm2.182 4.091v12.546h3.818v-6.077c0-2.037.75-3.332 2.553-3.332 1.3 0 1.81 1.201 1.81 3.332v6.077h3.819v-6.93c0-3.74-.895-5.78-4.667-5.78-1.967 0-3.277.921-3.788 1.946V9.818z">
                  </path>
                </svg>
              </div>
            </a>

            <a href="mailto:ashe@neth.org" target="_blank">
              <div class="icon" aria-hidden="true">
                <svg viewBox="0 0 36 27" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--text-color)>
                  <path d="M2.45453 26.9996H8.18176V13.0939L0 6.95898V24.5456C0 25.9014 1.0984 26.9996 2.45453 26.9996Z M0 3.68754V6.95947L8.18176 13.0943V2.46056L5.89087 0.742797C3.46293 -1.07722 0 0.654864 0 3.68754Z M8.18182 13.0947V2.46094L17.9999 9.82279L27.818 2.46094V13.0947L17.9999 20.4566L8.18182 13.0947Z M27.8182 2.46056V13.0943L36 6.95947V3.68754C36 0.654864 32.5371 -1.07722 30.1091 0.742797L27.8182 2.46056Z M27.8182 26.9996H33.5455C34.9016 26.9996 36 25.9014 36 24.5456V6.95898L27.8182 13.0939V26.9996Z">
                  </path>
                </svg>
              </div>
            </a>

            <a href="https://x.com/ashe_neth" target="_blank">
              <div class="icon" aria-hidden="true">
                <svg viewBox="0 0 1200 1227" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--text-color)>
                  <path d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z">
                  </path> 
                </svg>
              </div>
            </a>
          </div>
        </div>

        <p>
          I am an undergraduate computer science researcher at Worcester Polytechnic Institute (WPI, Class of 2025). I am currently looking for PhD positions for fall 2025. My primary research as of late surrounds creating high-performance platform-specific algorithms for machine learning and inference. My research interests include many forms of parallel computing such as high-performance computing, high-throughput computing, and multi-task computing, volunteer computing, resource-constrained computing, and distributed systems. My primary work so far has been on finding solutions to computing problems in resource-constrained environments and utilizing them in non-constrained environments. I aim to utilize the mindset that I have acquired while working with both resource-constrained and non-constrained systems to further the field of parallel computing.
        </p>
      </div>

      <h2>
        Papers:
      </h2>

      <div class="card-container">
        <div class="card">
          <p>
            <a href="./files/unit_pruner_preprint.pdf">
              UnIT Pruner: Unstructured Inference-Time Pruning for Battery-Free Systems
            </a>
            - Ashe Neth, Mohammad Nur Hossain Khan, Subrata Biswas, Asif Salekin, Bashima Islam
          </p>

          <p>
            Preprint:
            <a href="./files/unit_pruner_preprint.pdf">
              link
            </a>
          </p>

          <p>
            In Review - The ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2025)
          </p>

          <p>
            <img src="img/thumbnail/unit_pruner.jpg">

            With deep neural networks (DNNs) being increasingly deployed on low-resource devices, achieving efficiency without sacrificing accuracy has become a critical challenge. Model pruning, commonly performed during training, is a common approach to reducing model size and computational cost, even in environments where computational resources are not limited. However, traditional pruning methods are inherently static, often leading to accuracy losses that hinder their applicability in dynamic, real-world settings. Although some inference-time pruning techniques exist, these methods are generally structured, introducing similar accuracy compromises as conventional pruning methods.In this paper, we propose a novel, unstructured pruning algorithm that performs adaptive, input-specific pruning during inference: Unstructured Inference-Time Pruner (<text style="font-style: italic;">UnIT Pruner</text>). Unlike traditional approaches, <text style="font-style: italic;">UnIT Pruner</text> dynamicallyskips redundant operations in real time based on the unique properties of each input, allowing for efficient computation without significant accuracy trade-offs. Our algorithm can complement existing methods, enhancing the balance between energy efficiency and accuracy and, in certain systems, even reducing latency. Experimental results show that our method reduces MAC operations by 70.38–87.39% with as low as 0.43% accuracy drop. Additionally, we achieve 74.4–94.7% less inference time and consume 74.2–96.5% less energy on microcontrollers when compared to other pruning methods. Our proposed algorithm achieves state-of-the-art inferencetime pruning performance, demonstrating its effectiveness in deploying DNNs in resource-constrained environments.
          </p>
        </div>

        <div class="card">
          <p>
            <a href="https://arxiv.org/abs/2409.18978" target="_blank">
              Pronoun Logic
            </a>
            - Rose Bohrer, Ashe Neth
          </p>

          <p>
            Queer in AI Workshop at The Nations of the Americas Chapter of the Association for Computational Linguistics (Queer in AI @ NAACL 2024)
          </p>

          <p>
            arXiv:
            <a href="https://arxiv.org/abs/2409.18978" target="_blank">
              link
            </a>
          </p>

          <p>
            <img src="img/thumbnail/pronoun_logic.jpg">

            Historically, computational linguistics has been focused on rule-based semantics. This approach is still useful for parts of language that demand correctness such as with identity. This paper offers potential formalisms that would allow users to describe complex personal identities.
          </p>

          <p>
            Particularly in transgender and nonbinary (TGNB) communities, it is an increasingly common practice to publicly share one's personal pronouns so that we may be gendered correctly in others' speech. Many of us have nuanced desires for how we are gendered, leading us to use more complex descriptions of our wishes; for example, the descriptor 'she/they'.
          </p>

          <p>
            We observe that these descriptions of our wishes have the structure of a little language all their own. We thus propose formal logic as a tool for expressing one's personal pronouns and potentially other aspects of gender. We explore three potential logical foundations (linear logic, temporal logic, and free logic with definite descriptions) and their trade-offs.
          </p>
        </div>
      </div>

      <h2>
        Selected Projects:
      </h2>

      <div class="card-container">
        
        <!-- one CUDA section? -->

        <div class="card">
          <p>
            CUDA Neural Network
          </p>

          <p>
            Created a simple machine learning framework using CUDA.
          </p>

          <p>
            Experimented with several novel optimizer algorithms.
          </p>

          <p>
            Experimented with different ways of moving and storing memory on the GPU and its impact on processing speeds.
          </p>
        </div>

        <div class="card">
          <p>
            CUDA Ray Casting Engine
          </p>

          <p>
            Created a raycasting library using my CUDA/OpenGL interoperability library for writing to the screen and CUDA for the internal logic.
          </p>

          <p>
            Experimented with different ways of moving and storing memory on the GPU and its impact on processing speeds.
          </p>
        </div>

        <div class="card">
          <p>
            Library For CUDA/OpenGL Interoperability
          </p>

          <p>
            Created a CUDA/OpenGL interoperability library for simplifying the process of exposing framebuffers to CUDA via OpenGL pixelbuffers.
          </p>
        </div>
      </div>

      <!-- <h2>
        Silly Projects:
      </h2>

      <div class="card-container">
        <div class="card">
          <p>
            <a href="https://arxiv.org/abs/2409.13750">
              Undergrads Are All You Have
            </a>
            - Ashe Neth
          </p>

          <p>
            Initially created as a joke and published in SIGBOVIK, this paper explores the meaning of humanity and how large language models (LLMs) manage to exhibit it in spite of their very different architecture.
          </p>

          <p>The outsourcing of busy work and other research-related tasks to undergraduate students is a time-honored academic tradition. In recent years, these tasks have been given to Lama-based large-language models such as Alpaca and Llama increasingly often, putting poor undergraduate students out of work. Due to the costs associated with importing and caring for South American Camelidae, researcher James Yoo set out to find a cheaper and more effective alternative to these models. The findings, published in the highly-respected journal, SIGBOVIK, demonstrates that their model, GPT-UGRD is on par with, and in some cases better, than Lama models for natural language processing tasks. The paper also demonstrates that GPT-UGRD is cheaper and easier to train and operate than transformer models. In this paper, we outline the implementation, application, multi-tenanting, and social implications of using this new model in research and other contexts.
          </p>
        </div>
      </div> -->

      <!-- <p>
        COLOR SCHEME CREDIT:
      </p>

      <img src="img/color_scheme.jpg" width="25%">

      <div class="review-container">
        This is a peer-reviewed website:
        <div class="review">
          <p>
            "peak website" -cynth
          </p>
          <p>
            "i think you are bringing a new definition to 'scrolling twitter'" -cynth
          </p>
          <p>
            "this is better designed than the cybertruck" -alex
          </p>
        </div>
      </div>
    </div> -->

    <div class="footer">
      <div class="contact">
        <a href="https://github.com/asheneth" target="_blank">
          <div class="icon" aria-hidden="true">
            <svg viewBox="0 0 24 24" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--footer-text-color)>
              <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z">
              </path>
            </svg>
          </div>
        </a>

        <a href="https://www.linkedin.com/in/ashe-neth/" target="_blank">
          <div class="icon" aria-hidden="true">
            <svg viewBox="0 0 27 27" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--footer-text-color)>
              <path d="M1.91 0h22.363a1.91 1.91 0 011.909 1.91v22.363a1.91 1.91 0 01-1.91 1.909H1.91A1.91 1.91 0 010 24.272V1.91A1.91 1.91 0 011.91 0zm1.908 22.364h3.818V9.818H3.818zM8.182 5.727a2.455 2.455 0 10-4.91 0 2.455 2.455 0 004.91 0zm2.182 4.091v12.546h3.818v-6.077c0-2.037.75-3.332 2.553-3.332 1.3 0 1.81 1.201 1.81 3.332v6.077h3.819v-6.93c0-3.74-.895-5.78-4.667-5.78-1.967 0-3.277.921-3.788 1.946V9.818z">
              </path>
            </svg>
          </div>
        </a>

        <a href="mailto:ashe@neth.org" target="_blank">
          <div class="icon" aria-hidden="true">
            <svg viewBox="0 0 36 27" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--footer-text-color)>
              <path d="M2.45453 26.9996H8.18176V13.0939L0 6.95898V24.5456C0 25.9014 1.0984 26.9996 2.45453 26.9996Z M0 3.68754V6.95947L8.18176 13.0943V2.46056L5.89087 0.742797C3.46293 -1.07722 0 0.654864 0 3.68754Z M8.18182 13.0947V2.46094L17.9999 9.82279L27.818 2.46094V13.0947L17.9999 20.4566L8.18182 13.0947Z M27.8182 2.46056V13.0943L36 6.95947V3.68754C36 0.654864 32.5371 -1.07722 30.1091 0.742797L27.8182 2.46056Z M27.8182 26.9996H33.5455C34.9016 26.9996 36 25.9014 36 24.5456V6.95898L27.8182 13.0939V26.9996Z">
              </path>
            </svg>
          </div>
        </a>

        <a href="https://x.com/ashe_neth" target="_blank">
          <div class="icon" aria-hidden="true">
            <svg viewBox="0 0 1200 1227" width="100%" height="100%" preserveAspectRatio="xMidYMid meet" fill=var(--footer-text-color)>
              <path d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z">
              </path> 
            </svg>
          </div>
        </a>
      </div>
    </div>
  </body>
</html>